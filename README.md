# Fine-tuning ASR model for stuttering 

This project for the CMSE830 course at MSU focuses on enhancing Automatic Speech Recognition (ASR) systems to better handle disfluent speech, particularly stuttering-related disfluencies. Using the FluencyBank dataset, we fine-tuned the Wav2Vec 2.0 model, incorporating data augmentation strategies that simulate diverse speech patterns like word and phrase repetitions and interjections. By re-annotating the dataset for improved accuracy and augmenting it with synthesized stuttered speech samples, our group had achieved significant reductions in word error rates. Future work will involve the full fine-tuning to improve transcription accuracy and FBERT metrics.

